% \section{Implementation} \label{sec:impl}

% This section first introduces the implementation details of \xxx's \paxos 
% component, and then presents the implementation choices of the checkpoint 
% component.

% \subsection{\paxos Protocol} \label{sec:paxos}
% % SMR. Paxos. Choose it because: (1) fast. (2) transparent to applications.
% The \paxos consensus component is a critical component to enforce a 
% consistent 
% total order of socket operations from client programs. Although there are 
% already a number of open source \paxos implementations~\cite{concoord, 
% zookeeper, chubby:osdi, libpaxos}, we find it necessary to re-implement a 
% \paxos protocol because it is hard to port their current consensus 
% interface to \xxx's socket consensus interface.
% 
% 
% We have implemented a standard \paxos protocol based on a well-known approach 
% called ``\paxos Made Practical"~\cite{paxos:practical} because it is easy to 
% understand, use, and fast. In normal case, only the primary node is proposing 
% consensus requests, so consensus can be achieved fast. When exceptional cases 
% such as network partitions and node failures occur, a \paxos leader election 
% is 
% invoked to resolve conflicts. Each socket operation from the client is 
% assigned 
% a global, monotonically increasing viewstamp (or \emph{global index}) to 
% identify each checkpoint. Upon consensus on a socket operation, each 
% consensus 
% component persistently stores the operation type, arguments, and global index 
% into Berkeley DB storage on local SSD.



\section{Checkpoint and Rollback Design} \label{sec:checkpoint}

% Second, once an anlysis 
% captures some bad events caued by processing malicious inputs, \xxx must 
% allow % the analysis to invoke an operation to consistently roll back all 
% nodes's % execution states before this malicious input is being processed, 
% and % allow the % analysis to determine re-executing the inputs or discarding 
% the % inputs.

To transparently checkpoint an application, \xxx's checkpointer component 
leverages a popular, open source checkpoint-restore tool called 
\criu~\cite{criu}. This tool has supported CPU registers, memory, etc. However, 
one key issue still exists: a server constantly serves requests, and 
checkpointing and restoring TCP stacks on different machines is notoriously 
difficult. Our trick to avoid this difficulty is that we have observed that 
server programs always have some idle moments. Thus, a \xxx non-primary replica 
running an actual execution does a checkpoint periodically (one minute by 
default) when the replica has no alive socket connections.

For the checkpoint frequency on analysis nodes, we design it to be high, 
because: (1) analyses may need to roll back whenever detecting an malicious 
events; and (2) the time cost by a checkpoint operation does not matter much 
because the analysis is heavyweight anyway. Thus, a \xxx replica running an 
analysis performs a checkpoint at the moment the server has finished serving 
the current batch of socket connections: once the \paxos consensus component on 
each node finds that currently no socket connections are alive, the replica 
does a checkpoint. This checkpoint moment is also good for \xxx's rollback API 
because it helps the analysis get rid of the current socket connections which 
trigger the malicious events. 


% To meet the second requirement, we create an API that can be called by an 
% analysis tool to invoke a rollback. The API format is: \v{int} 
% \v{rollback(int} % \v{ncheckpoints = 0,} \v{bool skip = false)}. Once the 
% analysis calls this % operation, it invokes a client to send an roll back 
% operation to the primary node with the the list of the last checkpoint's 
% global % indexes. The primary then invokes a consensus on an internal roll 
% back % opration, % with the 
