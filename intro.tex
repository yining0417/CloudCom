\section{Introduction} \label{sec:intro}

% P1: virtualization is good
By simplifying provisioning and allowing multiple servers to be consolidated on a small 
number of physical hosts, virtualization has made low- and middle-end systems popular 
than ever. Nevertheless, the benefits of consolidation come with a hidden cost in the 
form of increased exposure to hardware failure. 

% P2: However, previous approaches still fail to efficiently and reliably provide fault-tolerance in virtualized environment

% To answer Heming's question: old leader and new leader get to an inconsistent state
% After recovery, the old leader should be started in the state as the new leader before participating

% 6.824 2016 mit
% What if the network between primary/backup fails?
%  -Primary is still running
%  -Backup becomes a new primary
%  -Two primaries at the same time!
% one can avoid split brain using a single "master"
% master computer decides whether replica A or replica B is the primary
%   there's just one master, so it never disagrees with itself
% clients talk to the master
% this is probably what VMware FT does (atomic test-and-set in shared disk)
% but what if the master fails?
%   it's a "single point of failure" -- not so good

There has been a tremendous progress in accommodating virtual machines with high availability, 
but existing works are still unable to ensure fault-tolerance in virtualized environment efficiently and reliably. 
One well-known technique is primary-backup based replication of virtual machines, where only the primary 
server executes all operations issued by the client and propagets to the backups the changes in the state. However, 
it suffers from two problems. First, 

% P3: log-replay is highly architecture-specific and slow for multi-processor

% requiring that the system have a comprehensive understanding of the instruction set being executed and the sources of external events.
% reproducing the exact order in which CPU cores access the shared memory

Log-replay records input and non-deterministic events of the primary machine and have them 
deterministically replayed on the backup machine to replicate the primary's state in case 
the primary node fails. However, deterministic replay is highly architecture-specific and 
introduces unacceptable performance degradation when applied in multi-core systems.

% P4: Checkpoint-recovery based replication of virtual machines, it suffers from two problems
% 1. network delay
% 2. significant VM downtimes
Checkpoint-recovery based replication of virtual machines is the other commonly used solution. 
It captures the entire execution state of the running VM at relatively high frequency so that 
changes can be reflected to the backup machine nearly instantly. However, it suffers from two 
problems. The first one is network delay. In order to address the output commit 
problem~\cite{strom1987volatile}, output of the running VM needs be held back until the primary 
host receives the acknowledgement of the corresponding update from the backup host. Apart from 
that, VM downtimes incurred by the checkpoint mechanism can be significant.

% P4: Our key insight is that instead of capturing snapshots of the running VM and propagating changes frequently, 
% enforcing the same ordering over network interaction from outside the VM at all nodes is sufficient to ensure fault tolerance
% Paxos, a consensus protocol, can help us achieve this
State Machine Replication (SMR) is a powerful fault-tolerance concept to address the aforementioned 
drawbacks of primary-backup based replication. SMR runs replicas of the program and invokes a 
distributed consensus protocol (typically \paxos) to ensure the same sequence of input requests 
for replicas, as long as a quorum (typically a majority) of the replicas agree on the input 
request sequence. Leveraging SMR. we have to address three practical challenges. 

First, \paxos is no notoriously is slow because each decision takes at least three message delays 
between when a replica proposes a command and when some replica learns which command has been chosen.

Fortunately, Remote Direct Memory Access (RDMA)-capable networks have dropped in price and made 
substantial inroads into datacenters. It allows one computer to directly access the memory of 
a remote computer without involving the operating system at any host. This enables zero-copy 
transfers, reducing latency and CPU overhead.

Second, to leverage existing SMR systems such as ZooKeeper, developes often have to shoehorn their 
programs into the narrowly defined state machine interfaces provided by these SMR systems. An SMR 
system often has to settle for a specific state and transitional interface because it cannot 
anticipate all the possibilities. Orchestrating a server program into such a narrow interface not 
only requires intrusive and error-prone modifications to the program's structure and code, but also 
disrupts the SMR system itself at times.

Third, to deal with nondeterminisim, SMR systems either reply on deterministic multithreading and replay 
approach~\cite{rex:eurosys14} or manually annotate all shared states to detect divergence of execution 
states~\cite{eve:osdi12}. These approaches lack automation or may incur high performance overhead.

This paper presents \xxx, a reliable high-performance SMR system that provides fault-tolerance 
in virtualized environment. Within each replica, \xxx interposes on the network syscalls to keep 
replicas in sync. Specifically, it considers each incoming network system call from outside the VM 
an input request, and runs a RDMA-based \paxos consensus protocol to ensure that a quorum of the 
replicas sees the same exact sequence of the incoming network syscalls. To tackle nondeterminism, 
\xxx intercepts the outgoing syscalls in the hypervisor and invokes an efficient network output 
checking protocol to detect divergence of execution states.

The remainder of the paper is organized as follows.
