\section{Introduction} \label{sec:intro}



% P1: dynamic program analysis framework is good. Traditional ones are 
% fully-coupled, but slow.
Dynamic program analysis frameworks greatly improve software quality as they
enable a wide range of powerful analysis tools (\eg, data race
detectors~\cite{tsan, valgrind:pldi, wester:parallelizing:asplos13} for
multithreaded applications) at runtime. Existing analysis frameworks can be
classified into two approaches depending on how a framework transfers an
application's execution states to an analysis tool. Traditional analysis
frameworks~\cite{dynamorio, pin:pldi05, valgrind:pldi, lift:micro06, tsan} take
a ``fully-coupled" approach: a framework in-lines an analysis with the
execution, then the analysis can inspect all or most execution states. However,
this approach can easily let the analysis slow down the actual execution. To
improve performance, leveraging a fact that many analyses can be done
asynchronously with the actual execution, some recent
frameworks~\cite{decouple:usenix08, speck:asplos08, 
shadowreplica:ccs13, wester:parallelizing:asplos13, superpin, jungwoo:oopsla09}
take a second ``partially-decoupled" approach: only analysis-critical execution
states (\eg, effective memory addresses and thread interleavings) are
transfered to the analysis running on other CPU cores, then the actual execution
can be less perturbed by the analysis.


% The second approach 
% is ``partially-decoupled" approach: to  improve performance, only a subset of 
 % frameworks because powerfuly analysis tend to be heavyweight and 
% prohibitively % slow down the execution.


Unfortunately, despite these great effort, most existing analysis frameworks are
still hard to deploy in production runs, mainly due to three problems. The first
problem is still performance. Traditional frameworks fully couple the analysis
with the actual execution using the shadow memory approach, so whenever an
analysis does some heavyweight work, the execution is slowed down (\eg, a
popular race detection tool ThreadSanitizer~\cite{tsan}, which uses a
traditional framework, incurs 20X$\sim$100X slowdown for many programs). Recent
frameworks that take the ``partially-decoupled" approach have shown to run
4X$\sim$8X times faster~\cite{shadowreplica:ccs13,
wester:parallelizing:asplos13} than traditional frameworks because they transfer
fewer 
execution states. However, the overall slowdown of these recent frameworks are
still prohibitive in their own evaluation because the amount of execution states
(\eg, effective memory addresses~\cite{shadowreplica:ccs13} and thread
interleavings~\cite{wester:parallelizing:asplos13}) transfered to analysis tools
are still enormous.


The second problem is that recent frameworks with the ``partially-decoupled"
approach heavily trade off transparency with analysis tools. To be able to
transfer fewer execution states to an analysis tool, these frameworks require
heavily carving the analysis tool as well as the transfered execution states.
For example, a recent framework~\cite{wester:parallelizing:asplos13} for race
detection tools leverages the record-replay
technique~\cite{scribe:sigmetrics2010, respec:asplos10, racepro:sosp11} to
reduce analysis work in the actual execution, but this framework
requires significantly carving race detection tools into several phases to adapt
to record-replay, which makes the tools largely different from typical ones
(Note that an analysis tool itself is already quite difficult to implement and
maintain.)


The third problem is that existing frameworks, including both traditional ones
and recent ones, have not shown to run multiple types of analysis tools 
together. Multiple analysis tools bring multiple powerful
guarantees, which is attractive to today's applications. However, the
traditional ``fully-coupled" frameworks typically take the shadow memory 
approach to hold analysis results for each memory byte in the actual execution, 
then different analyses may require different copies of shadow memory per byte. 
It is not trivial to extend these frameworks to support multiple copies of 
shadow memory. Considering ``partially-decoupled" frameworks, it is not trivial 
to extend them to support multiple types of analysis tools within one execution 
either, because these frameworks heavily carve the transfered execution states, 
which are hard to reuse for different types of analysis tools.


In sum, a fundamental reason for the three problems in existing analysis 
frameworks is that they run only one actual execution, so an analysis tool has
to be fully or partially coupled with the execution in order to inspect
execution states. Well, what if one can construct multiple equivalent
executions efficiently and transparently?




% P4: Our approach. Replication. DMT. And why we are better than existing 
% replication systems: avoid shipping schedules, avoid annotations.
To address this question, this paper presents \xxx, an efficient, 
transparent dynamic program analysis framework by leveraging a technique called 
\emph{transparent state machine replication}, presented in 
\repbox~\cite{repbox:sosp15}. This technique aims to provide a regular 
multithreaded application fault-tolerance benefits transparently without modifying 
this application. To do so, \repbox combines two techniques, \emph{state machine replication (or 
\smr)} and \emph{deterministic multithreading (or \dmt)}.


% To accomplish transparent state machine replication, \repbox leverages two key 
% techniques. The first one is \emph{state machine replication (or \smr)}, which assumes a deterministic 
% application and runs the application on multiple machines (or replicas). \smr 
% typically uses the \paxos~\cite{paxos} consensus protocol to enforce a 
% consistent sequence of inputs for the application across replicas, as long as a 
% majority of replicas reach consensus on each input. Thus, despite minor replica 
% failures, \smr still makes the replicated application available. To support general server 
%  applications transparently without modifying 
% them, \repbox creates a socket-API based \paxos consensus interface.


% However, for \repbox, \smr alone is not sufficient to support today's 
% applications which widely use threads and thus are nondeterministic. At runtime, 
% replicas may run into different thread interleavings (or \emph{schedules}), 
% easily leading to divergent execution states. To address this problem, \repbox 
% also leverages \emph{deterministic multithreading (or \dmt)}, a recent advanced 
% threading technique that efficiently enforce inter-thread communications to 
% happen in the same total order, then different replicas enforce the same schedules 
% on the same input.

Leveraging \repbox, \xxx can just run analysis tools on some replicas while the other replicas 
still run actual executions and process client requests fast. However, to achieve this goal, 
\xxx must address three practical challenges. First, even asynchronous analysis tools (\eg, race detectors) 
sometimes may decide to roll back to previous execution states and discard 
malicious inputs that triggered harmful events. To address this challenge, 
\xxx provides a transparent application-level checkpoint mechanism 
with expressive API for replicas to roll back consistently.

Second, it is unknown whether \xxx's replication techniques and analysis tools can benefit 
each other. To address this challenge, this paper discusses several types of 
analyses in which \xxx has the potential to strengthen and speedup existing 
tools themselves via \xxx's replication architecture. In addition, 
this paper points out that existing race detection tools can actually speedup 
\xxx. In a word, \xxx and existing analysis tools form a mutual benefitial 
eco-system.

Third, despite much effort, state-of-the-art still lacks evaluation to show that different types of 
analysis tools can actually run together. To address this challenge, we have conducted 
a feasibility study for \xxx in Linux. We evaulated on a popular parallel anti-virus 
scanning server \clamav~\cite{clamav} with three 
replicas (each has 24 cores) shows that \xxx is able to transparently run two 
analysis tools together: one is a heavyweight analysis tool, the Helgrind race 
detector~\cite{valgrind:pldi}; the other is a lightweight analysis tool, 
DynamoRio's code coverage tool drcov~\cite{dynamorio}. Moreover, \xxx incurred 
merely 2.1\% overhead over the actual execution.


% We have conducted a feasibility study for \xxx in Linux. To leverage \smr, 
% \xxx 
% incorporates a \paxos protocol implementation in 
% \repbox~\cite{repbox:sosp15}, 
% the first \smr system that transparently replicates server applications via 
% its 
% socket-API based \paxos consensus interface. Note that, unlike \repbox, \xxx 
% does \emph{not} aim to provide fault-tolerance, but aim to construct multiple 
% equivalent executions so that applications can enjoy efficient and 
% transparent 
% analyses. To leverage \dmt, \xxx incorporates \parrot~\cite{parrot:sosp13}, a 
% \dmt runtime system that has shown to run fast on a wide range of popular 
% multithreaded programs.




% P6: Benefits. This paragraph can be removed.
The main contribution of \xxx is the idea of applying transparent state 
machine replication to fully decouple 
an application's actual execution and analysis tools, which benefits 
applications, analysis tools, and frameworks. Note that: (1) unlike 
\repbox, \xxx does \emph{not} aim to provide fault-tolerance, but aims to 
construct multiple equivalent executions so that applications can enjoy 
efficient and transparent analyses; and (2) \xxx does not aim to replace 
traditional ``fully-coupled" frameworks, but aims to compensate them because \xxx 
can easily run them on replicas.


In the remaining of this paper, \S\ref{sec:background} introduces the 
background of the \repbox system. \S\ref{sec:overview} gives an overview of 
\xxx, including its deployment model, its checkpoint design for analysis 
tools, and its potential benefits. \S\ref{sec:eval} presents evaluation 
results, \S\ref{sec:related} introduces related work, and 
\S\ref{sec:conclusion} concludes.