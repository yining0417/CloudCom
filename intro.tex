\section{Introduction} \label{sec:intro}

% P1: virtualization is good
By simplifying provisioning and allowing multiple servers to be consolidated on a small 
number of physical hosts, virtualization has made low- and middle-end systems popular 
than ever. Nevertheless, the benefits of consolidation come with a hidden cost in the 
form of increased exposure to hardware failure. 

% P2: However, previous approaches still fail to efficiently provide fault-tolerance in virtualized environment

% There is no consistency problem
% One of the biggest additional components that must be designed is the mechanism for starting a backup VM in the same state as a primary VM
% This mechanism will also be used when restarting a backup VM after a failure has occurred

% 6.824 2016 mit
% What if the network between primary/backup fails?
%  -Primary is still running
%  -Backup becomes a new primary
%  -Two primaries at the same time!
% one can avoid split brain using a single "master"
% master computer decides whether replica A or replica B is the primary
%   there's just one master, so it never disagrees with itself
% clients talk to the master
% this is probably what VMware FT does (atomic test-and-set in shared disk)
% but what if the master fails?
%   it's a "single point of failure" -- not so good

There has been a tremendous progress in accommodating virtual machines with high availability, 
but existing works are still unable to ensure fault-tolerance in virtualized environment at 
low overhead. One typical technique is primary-backup based replication of virtual machines, 
including checkpoint-recovery based virtual machine replication and log-replay.

% P3: log-replay is highly architecture-specific and slow for multi-processor

% requiring that the system have a comprehensive understanding of the instruction set being executed and the sources of external events.
% reproducing the exact order in which CPU cores access the shared memory

Log-replay records input and non-deterministic events of the primary machine and have them 
deterministically replayed on the backup machine to replicate the primary's state in case 
the primary node fails. However, deterministic replay is highly architecture-specific and 
introduces unacceptable performance degradation when applied in multi-core systems.

% P4: Checkpoint-recovery based replication of virtual machines, it suffers from two problems
% 1. network delay
% 2. significant VM downtimes
Checkpoint-recovery based replication of virtual machines is the other commonly used solution. 
It captures the entire execution state of the running VM at relatively high frequency so that 
changes can be reflected to the backup machine nearly instantly. However, it suffers from two 
problems. The first one is network delay. In order to address the output commit 
problem~\cite{strom1987volatile}, output of the running VM needs be held back until the primary 
host receives the acknowledgement of the corresponding update from the backup host. Apart from 
that, VM downtimes incurred by the checkpoint mechanism can be significant.

% P4: Our key insight is that instead of capturing snapshots of the running VM and propagating changes frequently, 
% enforcing the same ordering over network interaction from outside the VM at all nodes is sufficient to ensure fault tolerance
% Paxos, a consensus protocol, can help us achieve this

To address the aforementioned problems, this paper presents REPVM, an SMR system that provides 
fault-tolerance in virtualized environment effciently.
Fortunately, Paxos, 
Thus, instead of 
enforcing the same ordering over network interaction from outside the VM at all nodes is 
sufficient fault tolerance. However, to achieve this goal, we have to address two practical 
challenges. First, Second, since Paxos is notoriously difficult to understand and implement, 
integrating Paxos within every service application is . To relieve the application programmer 
of the burden of structuring the application as a deterministic state machine, we need to 
enable state machine replication at the VM level rather than the application level.

% Note: limitation: cannot handle non-deterministic events.


% P6: However, traditional Paxos is slow
% Fortunately, RDMA opens new opportunity for mitigating consensus latency
However, Paxos consensus is notoriously difficult to be fast. 
To agree on an input, traditional consensus protocols invoke at least one 
message round-trip between two replicas. Fortunately, Remote Direct Access Memory (RDMA) opens new opportunity.

% P7: Besides, integrate Paxos within each application is notoriously difficult because it is difficult to understand and implement.
% We choose to intercept the network syscalls within the hypervisor.

% P8: We present a fast, fault-tolerant system.
% We intercept at the networking level and invoke RDMA-based Paxos protocol.

% P9: rest of the paper
